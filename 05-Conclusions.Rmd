# Conclusions

## Summary

In my disseration I have applied, adapted and extended the forward selection procedure under the marginality assumption first proposed by \cite{hao2014interaction} that is able to reduce search space substantially by making some reasonable assumptions about the data.  These assumptions can be relaxed a little to broaden the scope of the space. The procedure ahs been applied in both simulated and real datasets in all areas of study.  There are many advantages to using such a procedure with some being it is a computationally efficient way for high dimensional data situations that arise from high throughput data, especially when considering epistasis between gene markers or other type of interaction effects in the model.  Guided search space based off of commonly used principles in model selection that are relevant in real world situations. It is able to perform a GWAS with included epistatic interactions a fairly quick manner.  Able to relax assumptions to widen the search space.  This may decrease the speed of the algorithm but makes the search more comprehensive.  Also it is able to screen for complex scenarios that would be hard to find in a lab setting otherwise.  Having said that with the flexiblity of the initial model, false posiive rates could be a concern and need to be taken into consideration.  Adjustement to the significance level and the model selection criteria have been made to account for this.  This would still need to be followed up on independtly by checking with other datasets and/or lab verification.  

Functional componenets were also considered to such a selection procedure.  This also increases the computational complexity of the model and therefore decreases some efficeiency gains previously seen.  Use biologically relevant information to guide the fitting of the model.  Initially considers well established growth equations as a baseline for the underlying structure.  It then performs a GWAS level analysis with considering epstatic interactions throughout the process.  




## Discussion

The selection procedures proposed attempt to address problems that are complex and have many moving parts to the procedure.  Using a flexible model is very helpful to fulfill such requirements but this could have it be prone to over fitting at times if not well controlled.  Need to heavily consider this as part of interpretating the model.  Using stricter selection criteria and corrections to multuple testing for significance is extremely important.  The main purpose is to use a screening to guide future research, use for exploratory data analysis and hypothesis genration.  

With the complexity and expense that comes with genetic mapping, especially with a functional traits that needs repeatedly measured over time.  Correlation structures are inherent in this data that need be addressed and usually done so at a heavy computational cost.  Framing the problem as a regression problem and beingn able to use OLS calculations help to reduce the cost.  Verification steps are important steps especially with something as intricate as epistatic effects between gene markers.

Further investigations are needed to confirm or modify our findings by QTL mapping in natural populations.



**Also included in iFormFunctional Mapping Part**

Monitoring the change in expression patterns over time provides the distinct possibility of unraveling the mechanistic drivers characterizing cellular responses. Gene arrays measuring the level of mRNA expression of thousands of genes simultaneously provide a method of high-throughput data collection necessary for obtaining the scope of data required for understanding the complexities of living organisms. Unraveling the coherent complex structures of transcriptional dynamics is the goal of a large family of computational methods aiming at upgrading the information content of time-course gene expression data. In this review, we summarize the qualitative characteristics of these approaches, discuss the main challenges that this type of complex data present, and, finally, explore the opportunities in the context of developing mechanistic models of cellular response. \cite{androulakis2007analysis}





## Future Steps

More extensive explaination of future aims will be necessary for the final write up.  

### Aim 1

Incorporating other mean curves for the intercept term could help extend and relate to other areas of biology that follow a functional trait.  There are also other types of orthogonal polynomials that could be explored as well.  Using others polynomials would allow for other fits to the data that may be more applicable in other scenarios.  Also using other basis functions in general could open up opportunties for other areas of application.  


## Aim 2
Other interesting areas would be to consider different levels of interactions with other omics data.  Gene-gene interactions considered are only a portion of the picture and this type of modeling could also handle more levels of interactions that occur in a biological system.  One area that I am particularly interested in applying would be in methylation studies of the gene expression.  This level of interaction is very important and a selection procedure like the one proposed could help screen and generate of possible effects and hypothesis to continue to look into.  It would also apply in gene-environment interactions.  This does not have to be restricted to just within the biological system under study.  Environmental factors are important areas that could vastly impact the development of a phenotype.  


### Aim 3

Statistical areas that could as be considered to extend the model would be to include multivariate reponses to the system.  For example having gene and protein expression being a bivariate reponse and to see how genetic markers and epistasis between the markers would better predict this by taking the correlation between those two response variables into account.  Other statistical considerations would be to extend selection criteria to help further reduce the possibility of false positves being selected given a growing dataset like the one that occurs while dynamically including interaction effects throughout the selection.  Making the model even more computational efficient would always be benefical as well.  The faster a model can accurately run the more likely a researcher will use it.  It will also help process all the high throughput data that is being constantly developed.  

### Closing Remarks

Continuing on, my aim would be to work with datasets of this scale and incorporate the types of statistical methods mentioned and machine learning techniques to aid in analysis. The results could help gain larger insights into the genomic/epigenetic architecture of biological systems. On top of the importance of a functional component to the phenotype, considering other types of multivariate responses would be interesting to study in context of such a system. Integrating different level of omics data and the challenges that arise with such complicated and large datasets has interested me throughout my PhD work. Translating such a complex system into usable information that can be shared in order to prevent and fight disease would be ideal research for me. This type of research would need both methodological development as well as application of existing statistical and machine/deep learning techniques to handle the magnitude of the problem.
